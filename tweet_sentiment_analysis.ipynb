{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# natural language toolkit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('english'))\n",
    "from string import punctuation\n",
    "\n",
    "# import sklearn models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Logistic Regresion model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and laod Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data frame size:(1048575, 2)\n"
     ]
    }
   ],
   "source": [
    "# extract and load dataset\n",
    "DATASET_ZIP = 'Datasets/Tweets/tweets_data.zip'\n",
    "DATASET_TARGET = 'tweets'\n",
    "\n",
    "# helper extraction\n",
    "def extract_dataset(source_dir=DATASET_ZIP, target_dir=DATASET_TARGET):\n",
    "    # takes zip folder and unzips to target destination\n",
    "    try:\n",
    "        with zipfile.ZipFile(DATASET_ZIP,'r') as zip_ref:\n",
    "            zip_ref.extractall(DATASET_TARGET)\n",
    "    except IOError:\n",
    "        print('rror: File does not appear to exist.')\n",
    "\n",
    "# helper load function\n",
    "def load_dataset(source_dir, dataset_name, sep=','):\n",
    "    # loads csv data into pandas DataFrame\n",
    "    csv_path = os.path.join(source_dir, dataset_name)\n",
    "    tweets = pd.read_csv(csv_path,\n",
    "                         # for some reason the dataset has more than 2 unused columns\n",
    "                         # so we only get the first 2, class and text\n",
    "                         usecols=['Sentiment', 'SentimentText'],\n",
    "                         error_bad_lines=False,\n",
    "                         encoding='ISO-8859-1',\n",
    "                        )\n",
    "    return tweets\n",
    "\n",
    "# extract zip file\n",
    "extract_dataset(DATASET_ZIP, DATASET_TARGET)\n",
    "# and load data\n",
    "tweets = load_dataset(source_dir='tweets', dataset_name='tweets_sentiment.csv')\n",
    "\n",
    "print(f'data frame size:{tweets.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>or i just worry too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Sunny Again        Work Tomorrow  :-|  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>I must think about positive..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>this weekend has sucked so far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>jb isnt showing in australia any more!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>ok thats it you win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>&amp;lt;-------- This is the way i feel right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>awhhe man.... I'm completely useless rt no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>HUGE roll of thunder just now...SO scary!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>I just cut my beard off. It's only been gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>Very sad about Iran.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentiment                                      SentimentText\n",
       "0           0                       is so sad for my APL frie...\n",
       "1           0                     I missed the New Moon trail...\n",
       "3           0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4           0           i think mi bf is cheating on me!!!   ...\n",
       "5           0                  or i just worry too much?        \n",
       "7           0         Sunny Again        Work Tomorrow  :-|  ...\n",
       "10          0                      I must think about positive..\n",
       "12          0                     this weekend has sucked so far\n",
       "13          0             jb isnt showing in australia any more!\n",
       "14          0                               ok thats it you win.\n",
       "15          0      &lt;-------- This is the way i feel right ...\n",
       "16          0      awhhe man.... I'm completely useless rt no...\n",
       "18          0       HUGE roll of thunder just now...SO scary!!!!\n",
       "19          0      I just cut my beard off. It's only been gr...\n",
       "20          0                               Very sad about Iran."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print some positive samples\n",
    "tweets[tweets['Sentiment']==0].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>handed in my uniform today . i miss you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>hmmmm.... i wonder how she my number @-)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>thanks to all the haters up in my face a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Feeling strangely fine. Now I'm gonna go l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>You're the only one who can see this cause...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>goodbye exams, HELLO ALCOHOL TONIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>uploading pictures on friendster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>(: !!!!!! - so i wrote something last week. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>... Do I need to even say it?  Do I?  Well, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>... health class (what a joke!)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>@ginaaa &amp;lt;3 GO TO THE SHOW TONIGHT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>bathroom is clean..... now on to more enjoya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>boom boom pow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentiment                                      SentimentText\n",
       "2           1                            omg its already 7:30 :O\n",
       "6           1                 Juuuuuuuuuuuuuuuuussssst Chillin!!\n",
       "8           1        handed in my uniform today . i miss you ...\n",
       "9           1           hmmmm.... i wonder how she my number @-)\n",
       "11          1        thanks to all the haters up in my face a...\n",
       "17          1      Feeling strangely fine. Now I'm gonna go l...\n",
       "22          1      You're the only one who can see this cause...\n",
       "28          1              goodbye exams, HELLO ALCOHOL TONIGHT \n",
       "38          1                  uploading pictures on friendster \n",
       "41          1    (: !!!!!! - so i wrote something last week. ...\n",
       "43          1    ... Do I need to even say it?  Do I?  Well, ...\n",
       "44          1                    ... health class (what a joke!)\n",
       "45          1               @ginaaa &lt;3 GO TO THE SHOW TONIGHT\n",
       "51          1    bathroom is clean..... now on to more enjoya...\n",
       "52          1                                      boom boom pow"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print some negative samples\n",
    "tweets[tweets['Sentiment']==1].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to get some understanding of the data\n",
    "\n",
    "Before we do anything we could do some basic text clean up, like triming spaces and converting everything to lower case, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here a copy is created in order to do some data exploration\n",
    "data_exploration = tweets.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleanup(dataframe, text_column='SentimentText'):\n",
    "    \"\"\"\n",
    "    This function is meant to do some text cleaning:\n",
    "    Removes leading white spaces, HTML links, converts to lowercase.\n",
    "    \"\"\"\n",
    "    \n",
    "    # trim/strip left and right whitespaces\n",
    "    dataframe[text_column] = dataframe[text_column].str.strip()\n",
    "    # text to lowercase\n",
    "    dataframe[text_column] = dataframe[text_column].str.lower()\n",
    "    # removes hyperlinks - I will assume that they don't add much value\n",
    "    dataframe[text_column] = [re.sub(r'https?:\\/\\/.*\\/\\w*', '', w) for w in dataframe[text_column]]\n",
    "    # removes HTML special sintax such as &amp;\n",
    "    dataframe[text_column] = [re.sub(r'\\&\\w*;', '', w) for w in dataframe[text_column]]\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def tokenize_sentence(dataframe, text_column='SentimentText'):\n",
    "    \"\"\"\n",
    "    Converts sentence into list of words.\n",
    "    \"\"\"\n",
    "    dataframe[text_column] = [w.split() for w in dataframe['SentimentText']]\n",
    "    \n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply above data transformations:\n",
    "data_exploration = text_cleanup(data_exploration, text_column='SentimentText')\n",
    "data_exploration = tokenize_sentence(data_exploration, text_column='SentimentText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[is, so, sad, for, my, apl, friend.............]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[i, missed, the, new, moon, trailer...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[omg, its, already, 7:30, :o]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[.., omgaga., im, sooo, im, gunna, cry., i've,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[i, think, mi, bf, is, cheating, on, me!!!, t_t]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>[or, i, just, worry, too, much?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>[juuuuuuuuuuuuuuuuussssst, chillin!!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>[sunny, again, work, tomorrow, :-|, tv, tonight]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>[handed, in, my, uniform, today, ., i, miss, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>[hmmmm...., i, wonder, how, she, my, number, @-)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          0   [is, so, sad, for, my, apl, friend.............]\n",
       "1          0            [i, missed, the, new, moon, trailer...]\n",
       "2          1                      [omg, its, already, 7:30, :o]\n",
       "3          0  [.., omgaga., im, sooo, im, gunna, cry., i've,...\n",
       "4          0   [i, think, mi, bf, is, cheating, on, me!!!, t_t]\n",
       "5          0                   [or, i, just, worry, too, much?]\n",
       "6          1              [juuuuuuuuuuuuuuuuussssst, chillin!!]\n",
       "7          0   [sunny, again, work, tomorrow, :-|, tv, tonight]\n",
       "8          1  [handed, in, my, uniform, today, ., i, miss, y...\n",
       "9          1  [hmmmm...., i, wonder, how, she, my, number, @-)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_exploration.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\",\n",
    " 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers',\n",
    " 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which',\n",
    " 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been',\n",
    " 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if',\n",
    " 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off',\n",
    " 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all',\n",
    " 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own',\n",
    " 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\",\n",
    " 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\",\n",
    " 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn',\n",
    " \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\",\n",
    " 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exploration.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is feature engineering... to try to get a relationship between length of the tweet and sentiment\n",
    "# get a word count per sentence column\n",
    "def word_count(sentence):\n",
    "    return len(sentence.split())\n",
    "    \n",
    "tweets['word count'] = tweets['text'].apply(word_count)\n",
    "tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot word count distribution for both positive and negative sentiments\n",
    "x = tweets['word count'][tweets.Sentiment == 1]\n",
    "y = tweets['word count'][tweets.Sentiment == 0]\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.xlim(0,45)\n",
    "plt.xlabel('word count')\n",
    "plt.ylabel('frequency')\n",
    "g = plt.hist([x, y], color=['r','b'], alpha=0.5, label=['positive','negative'])\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize helper function\n",
    "def text_process(text):\n",
    "    \n",
    "    # Check characters to see if they are punctuation\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # removes stopwords \n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    return clean_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean tweets\n",
    "def cleanse_tweet(tweet):\n",
    "    # Removes HTML special entities (e.g. &amp;)\n",
    "    tweet = re.sub(r'\\&\\w*;', '', tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','',tweet)\n",
    "    # Remove tickers\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # To lowercase\n",
    "    tweet = tweet.lower()\n",
    "    # Remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*\\/\\w*', '', tweet)\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)\n",
    "    # Remove Punctuation and split 's, 't, 've with a space for filter\n",
    "    tweet = re.sub(r'[' + punctuation.replace('@', '') + ']+', ' ', tweet)\n",
    "    # Remove words with 2 or fewer letters\n",
    "    tweet = re.sub(r'\\b\\w{1,2}\\b', '', tweet)\n",
    "    # Remove whitespace (including new line characters)\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "    # Remove single space remaining at the front of the tweet.\n",
    "    tweet = tweet.lstrip(' ') \n",
    "    # Remove characters beyond BMP of Unicode:\n",
    "    tweet = ''.join(c for c in tweet if c <= '\\uFFFF')\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clense tweet, remove special characters using regex\n",
    "tweets['text'] = tweets['text'].apply(cleanse_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train:test split, 80:20 \n",
    "msg_train, msg_test, class_train, class_test = train_test_split(tweets['text'],\n",
    "                                                                tweets['Sentiment'],\n",
    "                                                                test_size=0.2)\n",
    "\n",
    "msg_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Test\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)), # converts strings to integer counts\n",
    "    ('tfidf',TfidfTransformer()), # converts integer counts to weighted TF-IDF scores\n",
    "    ('classifier',BernoulliNB()) # train on TF-IDF vectors with Naive Bayes classifier\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(msg_train,class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(class_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes accuracy\n",
    "print('Naive Bayes:\\n\\t Accuracy ~ {0:.2f}%'.format(np.mean(predictions == class_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(class_test,predictions),annot=True, fmt='g')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logistic regresion pipeline\n",
    "text_clf_LogisticRegression = Pipeline([('vect', CountVectorizer(analyzer=text_process, ngram_range=(2,4), stop_words='english',lowercase=True)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LogisticRegression()),])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "text_clf_LogisticRegression.fit(msg_train,class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "predicted_LogisticRegression = text_clf_LogisticRegression.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(class_test,predicted_LogisticRegression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "print('Logistic Regression:\\n\\t Accuracy ~ {0:.2f}%'.format(np.mean(predicted_LogisticRegression == class_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(class_test,predicted_LogisticRegression),annot=True, fmt='g')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
